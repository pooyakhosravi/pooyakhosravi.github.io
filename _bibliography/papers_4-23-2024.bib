@inproceedings{sun2024hybrid,
  title={Hybrid-CSR: Coupling Explicit and Implicit Reconstruction of Cortical Surface.},
  author={Sun, Shanlin and Le, Tung and Khosravi, Pooya and You, Chenyu and Han, Kun and Ma, Haoyu and Kong, Deying and Yan, Xiangyi and Xie, Xiaohui},
  booktitle={BMVC},
  year={2024}
}

@article{khosravi2024external,
  title={External Validation of Deep Learning Models for Classifying Etiology of Retinal Hemorrhage Using Diverse Fundus Photography Datasets},
  author={Khosravi, Pooya and Huck, Nolan A and Shahraki, Kourosh and Ghafari, Elina and Azimi, Reza and Kim, So Young and Crouch, Eric and Xie, Xiaohui and Suh, Donny W},
  journal={Bioengineering},
  volume={12},
  number={1},
  pages={20},
  year={2024},
  publisher={MDPI}
}

@article{robbins2025trends,
  title={Trends in Demographic, Clinical, Socioeconomic, and Facility-Specific Factors Linked to Eyelid Melanoma Survival: A National Cancer Database Analysis},
  author={Robbins, James O and Huck, Nolan A and Khosravi, Pooya and Torabi, Sina J and Woodward, Julie A and Kuan, Edward C and Dermarkarian, Christopher R},
  journal={Ophthalmic Plastic \& Reconstructive Surgery},
  pages={10--1097},
  publisher={LWW}
}


@article{goshtasbi2025smartphone,
  title={Smartphone-Based Cognitive Behavioral Therapy and Customized Sound Therapy for Tinnitus: A Randomized Controlled Trial},
  author={Goshtasbi, Khodayar and Tawk, Karen and Khosravi, Pooya and Abouzari, Mehdi and Djalilian, Hamid R},
  journal={Annals of Otology, Rhinology \& Laryngology},
  volume={134},
  number={2},
  pages={125--133},
  year={2025},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@inproceedings{khosravi2025xoct,
  title={XOCT: Enhancing OCT to OCTA Translation via Cross-Dimensional Supervised Multi-scale Feature Learning},
  author={Khosravi, Pooya and Han, Kun and Wu, Anthony T and Rezvani, Arghavan and Feng, Zexin and Xie, Xiaohui},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={695--705},
  year={2025},
  organization={Springer}
}


@inproceedings{nikzamir2025robust,
  title={A Robust Miniaturized Multi-Chip Module with Wireless Data and Power Transfer for Precise and Safe Tinnitus Therapy},
  author={Nikzamir, A and Cao, Y and Moradi, B and Khosravi, P and Djalilian, H and Green, MM},
  booktitle={2025 Nineteenth International Congress on Artificial Materials for Novel Wave Phenomena (Metamaterials)},
  pages={X--233},
  year={2025},
  organization={IEEE}
}

@article{hucksurvival,
  title={Survival Outcomes of 997 Patients With Eyelid Sebaceous Carcinoma in the National Cancer Database},
  author={Huck, Nolan A and Khosravi, Pooya and Torabi, Sina J and Zhou, Paul S and Nguyen, Theodore V and Tao, Jeremiah P and Kuan, Edward C and Dermarkarian, Christopher R},
  journal={The Journal of craniofacial surgery}
}


@article{https://doi.org/10.1002/alr.23354,
author = {Miller, Jessa E. and Chung, Hye Rhyn and Uy, Benjamin R. and Kosaraju, Nikitha and Shih, Ryan M. and Ko, Myungjun and Esswein, Shannon R. and Abiri, Arash and Khosravi, Pooya and Huck, Nolan and Nguyen, Cecilia H. and Hsu, Timothy and Kim, Michael G. and Hsu, Frank P. K. and Kim, Won and Lee, Jivianne K. and Suh, Jeffrey D. and Bergsneider, Marvin and Kuan, Edward C. and Wang, Marilene B.},
title = {Comparison of patient-reported outcomes and clinical characteristics among patients with pituitary macroadenomas and giant adenomas},
journal = {International Forum of Allergy \& Rhinology},
pages = {},
year={2024},
abbr={IFAR},
keywords = {anterior skull base, endoscopic skull base surgery, patient reported outcome measure, SNOT-22},
doi = {https://doi.org/10.1002/alr.23354},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/alr.23354},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/alr.23354},
abstract = {Key Points Patients with giant adenomas are more likely to have tumor extension into the paranasal sinuses. Compared to macroadenomas, giant adenomas are not associated with worse preoperative SNOT-22 scores.}
}



@article{BITNER2024104133,
title = {Impact of facility volume on survival in primary endoscopic surgery for sinonasal squamous cell carcinoma},
journal = {American Journal of Otolaryngology},
volume = {45},
number = {2},
pages = {104133},
year = {2024},
abbr={AJO},
issn = {0196-0709},
doi = {https://doi.org/10.1016/j.amjoto.2023.104133},
url = {https://www.sciencedirect.com/science/article/pii/S0196070923003472},
author = {Benjamin F. Bitner and Nolan A. Huck and Pooya Khosravi and Sina J. Torabi and Eric H. Abello and Khodayar Goshtasbi and Edward C. Kuan},
keywords = {Sinonasal squamous cell carcinoma, Endoscopic, Hospital volume, Outcomes, Overall survival, Academic facility, National Cancer DataBase},
abstract = {Objectives
To evaluate the impact of facility volume on outcomes following primary endoscopic surgical management of sinonasal squamous cell carcinoma (SNSCC).
Methods
The 2010–2016 National Cancer DataBase (NCDB) was queried for patients diagnosed with T1-T4a SNSCC surgically treated endoscopically as the primary treatment modality. Factors associated with overall survival (OS) were evaluated, including facility volume.
Results
A total of 330 patients who underwent endoscopic surgical management of SNSCC were treated at 356 unique facilities designated as either low-volume (LVC; treating 1–2 cases; 0-75th percentile), intermediate-volume centers (IVC; 3–4 cases total; 75th–90th percentile), or 144 high-volume (HVC; treating 5+ cases total; >90th percentile) centers. HVC treated patients with higher T staging (42.1 % vs. 29.8 %) and tumors in the maxillary sinus (26.9 % vs. 13.2 %) and ethmoid sinus (10.3 % vs. ≤8.3 %), while LVCs treated lower T stage tumors (70.2 % vs. 57.9 %) and tumors that were located in the nasal cavity (70.2–78.5 % vs. 62.8 %). On multivariable analysis, factors associated with decreased OS included higher T stage (T3/T4a vs. T1/T2; OR 1.92, 95 % CI 1.06–3.47) and older age (>65 vs. <65; OR 2.69, 95 % CI 1.62–4.49). Cases treated at high-volume centers were not associated with a higher likelihood of OS when compared to low-volume centers (OR 0.70, 95 % CI 0.36–1.35).
Conclusions
HVC are treating more primary tumors of the maxillary and ethmoid sinuses and tumors with higher T stages with endoscopic approaches, although this does not appear to be associated with increased OS.
Short summary
Sinonasal squamous cell carcinoma (SNSCC) presents late in disease process with poor prognosis. We investigated the impact of facility volume on outcomes following endoscopic treatment of SNSCC. High-volume centers treat more advanced and complex disease with comparable OS.}
}


@Article{ijms242015105,
AUTHOR = {Khosravi, Pooya and Huck, Nolan A. and Shahraki, Kourosh and Hunter, Stephen C. and Danza, Clifford Neil and Kim, So Young and Forbes, Brian J. and Dai, Shuan and Levin, Alex V. and Binenbaum, Gil and Chang, Peter D. and Suh, Donny W.},
TITLE = {Deep Learning Approach for Differentiating Etiologies of Pediatric Retinal Hemorrhages: A Multicenter Study},
JOURNAL = {International Journal of Molecular Sciences},
VOLUME = {24},
YEAR = {2023},
NUMBER = {20},
ARTICLE-NUMBER = {15105},
URL = {https://www.mdpi.com/1422-0067/24/20/15105},
ISSN = {1422-0067},
abbr={IJMS},
selected={true},
ABSTRACT = {Retinal hemorrhages in pediatric patients can be a diagnostic challenge for ophthalmologists. These hemorrhages can occur due to various underlying etiologies, including abusive head trauma, accidental trauma, and medical conditions. Accurate identification of the etiology is crucial for appropriate management and legal considerations. In recent years, deep learning techniques have shown promise in assisting healthcare professionals in making more accurate and timely diagnosis of a variety of disorders. We explore the potential of deep learning approaches for differentiating etiologies of pediatric retinal hemorrhages. Our study, which spanned multiple centers, analyzed 898 images, resulting in a final dataset of 597 retinal hemorrhage fundus photos categorized into medical (49.9%) and trauma (50.1%) etiologies. Deep learning models, specifically those based on ResNet and transformer architectures, were applied; FastViT-SA12, a hybrid transformer model, achieved the highest accuracy (90.55%) and area under the receiver operating characteristic curve (AUC) of 90.55%, while ResNet18 secured the highest sensitivity value (96.77%) on an independent test dataset. The study highlighted areas for optimization in artificial intelligence (AI) models specifically for pediatric retinal hemorrhages. While AI proves valuable in diagnosing these hemorrhages, the expertise of medical professionals remains irreplaceable. Collaborative efforts between AI specialists and pediatric ophthalmologists are crucial to fully harness AI&rsquo;s potential in diagnosing etiologies of pediatric retinal hemorrhages.},
DOI = {10.3390/ijms242015105}
}

@InProceedings{10.1007/978-3-031-43907-0_72,
author="Han, Kun
and Xiong, Yifeng
and You, Chenyu
and Khosravi, Pooya
and Sun, Shanlin
and Yan, Xiangyi
and Duncan, James S.
and Xie, Xiaohui",
editor="Greenspan, Hayit
and Madabhushi, Anant
and Mousavi, Parvin
and Salcudean, Septimiu
and Duncan, James
and Syeda-Mahmood, Tanveer
and Taylor, Russell",
title="MedGen3D: A Deep Generative Framework for Paired 3D Image and Mask Generation",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2023",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="759--769",
abbr={MICCAI},
selected={true},
abstract="Acquiring and annotating sufficient labeled data is crucial in developing accurate and robust learning-based models, but obtaining such data can be challenging in many medical image segmentation tasks. One promising solution is to synthesize realistic data with ground-truth mask annotations. However, no prior studies have explored generating complete 3D volumetric images with masks. In this paper, we present MedGen3D, a deep generative framework that can generate paired 3D medical images and masks. First, we represent the 3D medical data as 2D sequences and propose the Multi-Condition Diffusion Probabilistic Model (MC-DPM) to generate multi-label mask sequences adhering to anatomical geometry. Then, we use an image sequence generator and semantic diffusion refiner conditioned on the generated mask sequences to produce realistic 3D medical images that align with the generated masks. Our proposed framework guarantees accurate alignment between synthetic images and segmentation maps. Experiments on 3D thoracic CT and brain MRI datasets show that our synthetic data is both diverse and faithful to the original data, and demonstrate the benefits for downstream segmentation tasks. We anticipate that MedGen3D's ability to synthesize paired 3D medical images and masks will prove valuable in training deep learning models for medical imaging tasks.",
isbn="978-3-031-43907-0"
}

@article{lehrich2018fetal,
  title={Fetal bovine serum-derived extracellular vesicles persist within vesicle-depleted culture media},
  author={Lehrich, Brandon M and Liang, Yaxuan and Khosravi, Pooya and Federoff, Howard J and Fiandaca, Massimo S},
  journal={International journal of molecular sciences},
  volume={19},
  number={11},
  pages={3538},
  year={2018},
  abbr={IJMS},
  publisher={MDPI}
}

@article{birkenbeuel2019medical,
  title={Medical malpractice of vestibular schwannoma: a 40-year review of the United States legal databases},
  author={Birkenbeuel, Jack and Vu, Kimberly and Lehrich, Brandon M and Abouzari, Mehdi and Cheung, Dillon and Khosravi, Pooya and Sahyouni, Ronald and Ziai, Kasra and Moshtaghi, Omid and Sahyouni, Sammy and others},
  journal={Otology \& neurotology: official publication of the American Otological Society, American Neurotology Society [and] European Academy of Otology and Neurotology},
  volume={40},
  number={3},
  pages={391},
  year={2019},
  publisher={NIH Public Access}
}

@article{abouzari2020prediction,
  title={Prediction of vestibular schwannoma recurrence using artificial neural network},
  author={Abouzari, Mehdi and Goshtasbi, Khodayar and Sarna, Brooke and Khosravi, Pooya and Reutershan, Trevor and Mostaghni, Navid and Lin, Harrison W and Djalilian, Hamid R},
  journal={Laryngoscope Investigative Otolaryngology},
  year={2020},
  publisher={John Wiley \& Sons, Inc.}
}

@article{abouzari2021adapting,
  title={Adapting personal therapies using a mobile application for tinnitus rehabilitation: a preliminary study},
  author={Abouzari, Mehdi and Goshtasbi, Khodayar and Sarna, Brooke and Ghavami, Yaser and Parker, Erica M and Khosravi, Pooya and Mostaghni, Navid and Jamshidi, Shahrnaz and Saber, Tina and Djalilian, Hamid R},
  journal={Annals of Otology, Rhinology \& Laryngology},
  volume={130},
  number={6},
  pages={571--577},
  year={2021},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}



@article{tsutsumi2021web,
  title={A web-based deep learning model for automated diagnosis of otoscopic images},
  author={Tsutsumi, Kotaro and Goshtasbi, Khodayar and Risbud, Adwight and Khosravi, Pooya and Pang, Jonathan C and Lin, Harrison W and Djalilian, Hamid R and Abouzari, Mehdi},
  journal={Otology \& Neurotology},
  volume={42},
  number={9},
  pages={e1382--e1388},
  year={2021},
  publisher={LWW}
}

@article{tsutsumi2022machine,
  title={Machine Learning in the Management of Lateral Skull Base Tumors: A Systematic Review},
  author={Tsutsumi, Kotaro and Soltanzadeh-Zarandi, Sina and Khosravi, Pooya and Goshtasbi, Khodayar and Djalilian, Hamid R and Abouzari, Mehdi},
  journal={Journal of Otorhinolaryngology, Hearing and Balance Medicine},
  volume={3},
  number={4},
  pages={7},
  year={2022},
  abbr={OHBM},
  publisher={MDPI}
}

@article{kamalipour2023deep,
  title={Deep learning estimation of 10-2 visual field map based on circumpapillary retinal nerve fiber layer thickness measurements},
  author={Kamalipour, Alireza and Moghimi, Sasan and Khosravi, Pooya and Jazayeri, Mohammad Sadegh and Nishida, Takashi and Mahmoudinezhad, Golnoush and Li, Elizabeth H and Christopher, Mark and Liebmann, Jeffrey M and Fazio, Massimo A and others},
  journal={American Journal of Ophthalmology},
  volume={246},
  pages={163--173},
  year={2023},
  abbr={AJO},
  selected={true},
  publisher={Elsevier}
}

@article{kamalipour2023combining,
  title={Combining Optical Coherence Tomography and Optical Coherence Tomography Angiography Longitudinal Data for the Detection of Visual Field Progression in Glaucoma},
  author={Kamalipour, Alireza and Moghimi, Sasan and Khosravi, Pooya and Mohammadzadeh, Vahid and Nishida, Takashi and Micheletti, Eleonora and Wu, Jo-Hsuan and Mahmoudinezhad, Golnoush and Li, Elizabeth HF and Christopher, Mark and others},
  journal={American Journal of Ophthalmology},
  volume={246},
  pages={141--154},
  abbr={AJO},
  selected={true},
  year={2023},
  publisher={Elsevier}
}


@article{tsutsumi2023artificial,
  title={Artificial neural network prediction of post-thyroidectomy outcome},
  author={Tsutsumi, Kotaro and Goshtasbi, Khodayar and Ahmed, Khwaja H and Khosravi, Pooya and Tawk, Karen and Haidar, Yarah M and Tjoa, Tjoson and Armstrong, William B and Abouzari, Mehdi},
  journal={Clinical Otolaryngology},
  year={2023}
}


@article{https://doi.org/10.1002/ohn.812,
author = {Torabi, Sina J. and Hong, Ellen M. and Patel, Rahul A. and Nguyen, Theodore V. and Huck, Nolan A. and Khosravi, Pooya and Peter Manes, R. and Kuan, Edward C.},
title = {How Variable are Patient Comorbidity Profiles Among Practicing Otolaryngologists?},
journal = {Otolaryngology–Head and Neck Surgery},
volume = {n/a},
number = {n/a},
pages = {},
year={2024},
abbr={OHNS},
keywords = {comorbidity, disparities, hierarchical condition category, Medicare, otolaryngology},
doi = {https://doi.org/10.1002/ohn.812},
url = {https://aao-hnsfjournals.onlinelibrary.wiley.com/doi/abs/10.1002/ohn.812},
eprint = {https://aao-hnsfjournals.onlinelibrary.wiley.com/doi/pdf/10.1002/ohn.812},
abstract = {Abstract Objective To determine whether certain groups of otolaryngologists (ORLs) are treating cohorts of patients with more comorbidities. Study Design Cross-sectional population-based analysis. Setting 2019 Medicare Provider Utilization and Payment Dataset. Methods Each ORL's average Medicare hierarchical condition category (HCC) risk score, a comorbidity index calculated from a patient's comorbidities, was collected. These were stratified and compared by various physician characteristics, including practice region and rurality, years in practice, gender, subspecialty, and setting (academic vs community). Results Among 8959 ORLs, the mean HCC risk score for Medicare patients was 1.35 ± 0.35. On univariate analysis, ORLs practicing in urban (compared to rural), ORLs in academic settings (compared to community), and early career ORLs all had a patient population with a higher HCC risk score (P < .001 for all). On multivariate analysis controlling for gender, rurality, graduation year, and region, rural setting was associated with decreased odds of having a high-risk patient population (odds ratio: 0.58 [95\% confidence interval, CI: 0.48-0.71]; P < .001), while those more recently graduated has an increased risk (2000-2009: 1.41 [1.01-1.96], P = .046; 2010-2015: 2.30 [1.63-3.25], P < .001). In a separate subgroup analysis, subspecialty differences were seen and community setting was associated with decreased odds of having a high-risk patient population (0.36 [0.23-0.55]; P < .001). Conclusion There is variability in patient comorbidity profiles among ORLs, with those in urban settings, those more recently graduated, and those in academic settings treating a group with more comorbidities. As the comorbidity burden may increase the cost of practice and complications, these findings may have important implications for health inequity.}
}

@article{KAMALIPOUR2024,
title = {Retinal Nerve Fiber Layer Optical Texture Analysis and 10-2 Visual Field Assessment in Glaucoma},
journal = {American Journal of Ophthalmology},
year = {2024},
issn = {0002-9394},
abbr={AJO},
selected={true},
doi = {https://doi.org/10.1016/j.ajo.2024.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0002939424002204},
author = {Alireza Kamalipour and Sasan Moghimi and Pooya Khosravi and Natchada Tansuebchueasai and Cristiana Vasile and Mohsen Adelpour and Gopikasree Gunasegaran and Takashi Nishida and Linda M. Zangwill and Alexander K.N. Lam and Christopher K.S. Leung and Robert N. Weinreb},
keywords = {Glaucoma, Retinal Nerve Fiber Layer Optical Texture Analysis, ROTA, Retinal Nerve Fiber Layer, OCT, Visual Field, 10-2, 24-2, Structure-Function Relationship},
abstract = {Purpose
To apply retinal nerve fiber layer (RNFL) optical texture analysis (ROTA) to 1) investigate the association between papillomacular and papillofoveal bundle defects with 10-2 visual field (VF) sensitivity abnormalities, and 2) integrate the information from RNFL bundle defect and 24-2 VF central test locations to determine the likelihood of 10-2 VF sensitivity abnormalities.
Design
Cross-sectional
Methods
A total of 841 eyes (144 healthy, 317 glaucoma suspect, and 380 glaucoma) of 442 participants were included. Eyes underwent 24-2, and 10-2 VF testing and OCT for ROTA. The borders of RNFL defects were delineated from ROTA, and the involvement of the arcuate, papillomacular, and papillofoveal bundles was determined for each eye. Multilevel logistic regression analysis was applied to evaluate the structure–function association.
Results
Papillomacular (92.1%) and papillofoveal (37.9%) RNFL bundle defects were prevalent in eyes with glaucoma. A 10-2 VF location that was projected onto a papillomacular or a papillofoveal RNFL bundle defect had a significantly increased likelihood of reduced sensitivity (ORs of 18.61 at PDP < 5%, and 20.17 at TDP < 5%, respectively, P < 0.001 for both). When predicting the likelihood of VF abnormality in a 10-2 test location, noticeably higher odds ratios were observed when overlapping with an RNFL bundle defect, compared to when an abnormal corresponding 24-2 central point was present.
Conclusions
Papillomacular and papillofoveal RNFL bundle defects are present in a considerable proportion of eyes with glaucoma. When detected, they significantly increase the likelihood of abnormality in the corresponding central VF test locations assessed by the 10-2 test.}
}


@article{SUN2024103249,
title = {Medical image registration via neural fields},
journal = {Medical Image Analysis},
volume = {97},
pages = {103249},
year = {2024},
abr = {MIA},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2024.103249},
url = {https://www.sciencedirect.com/science/article/pii/S1361841524001749},
author = {Shanlin Sun and Kun Han and Chenyu You and Hao Tang and Deying Kong and Junayed Naushad and Xiangyi Yan and Haoyu Ma and Pooya Khosravi and James S. Duncan and Xiaohui Xie},
keywords = {Optimization, Neural fields, Deformable image registration, Neural ODEs, Hybrid Coordinate samplers},
abstract = {Image registration is an essential step in many medical image analysis tasks. Traditional methods for image registration are primarily optimization-driven, finding the optimal deformations that maximize the similarity between two images. Recent learning-based methods, trained to directly predict transformations between two images, run much faster, but suffer from performance deficiencies due to domain shift. Here we present a new neural network based image registration framework, called NIR (Neural Image Registration), which is based on optimization but utilizes deep neural networks to model deformations between image pairs. NIR represents the transformation between two images with a continuous function implemented via neural fields, receiving a 3D coordinate as input and outputting the corresponding deformation vector. NIR provides two ways of generating deformation field: directly output a displacement vector field for general deformable registration, or output a velocity vector field and integrate the velocity field to derive the deformation field for diffeomorphic image registration. The optimal registration is discovered by updating the parameters of the neural field via stochastic mini-batch gradient descent. We describe several design choices that facilitate model optimization, including coordinate encoding, sinusoidal activation, coordinate sampling, and intensity sampling. NIR is evaluated on two 3D MR brain scan datasets, demonstrating highly competitive performance in terms of both registration accuracy and regularity. Compared to traditional optimization-based methods, our approach achieves better results in shorter computation times. In addition, our methods exhibit performance on a cross-dataset registration task, compared to the pre-trained learning-based methods.}
}
